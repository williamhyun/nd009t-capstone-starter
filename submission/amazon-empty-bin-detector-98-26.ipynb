{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install required packages","metadata":{}},{"cell_type":"code","source":"!pip3 install -U timm torchvision > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T19:59:14.711687Z","iopub.execute_input":"2022-05-08T19:59:14.712021Z","iopub.status.idle":"2022-05-08T20:00:37.194480Z","shell.execute_reply.started":"2022-05-08T19:59:14.711926Z","shell.execute_reply":"2022-05-08T20:00:37.193627Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load medatadata","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport sqlite3\n\nconn = sqlite3.connect(\"../input/amazon-bin-image-dataset-536434-images-224x224/metadata.db\")\ndf = pd.read_sql_query(\"SELECT name, json_extract(metadata, '$.EXPECTED_QUANTITY') quantity FROM metadata WHERE quantity < 2\", conn)\nconn.close()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:37.196541Z","iopub.execute_input":"2022-05-08T20:00:37.196744Z","iopub.status.idle":"2022-05-08T20:00:50.380289Z","shell.execute_reply.started":"2022-05-08T20:00:37.196719Z","shell.execute_reply":"2022-05-08T20:00:50.379605Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"             name  quantity\n0           1.jpg         0\n1           2.jpg         0\n2           3.jpg         0\n3           4.jpg         0\n4           5.jpg         0\n...           ...       ...\n51243  535178.jpg         1\n51244  535185.jpg         0\n51245  535192.jpg         1\n51246  535196.jpg         1\n51247  535202.jpg         1\n\n[51248 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>quantity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51243</th>\n      <td>535178.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51244</th>\n      <td>535185.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51245</th>\n      <td>535192.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51246</th>\n      <td>535196.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51247</th>\n      <td>535202.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>51248 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Check class distribution","metadata":{}},{"cell_type":"code","source":"df.quantity.hist()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:50.385182Z","iopub.execute_input":"2022-05-08T20:00:50.387625Z","iopub.status.idle":"2022-05-08T20:00:50.748498Z","shell.execute_reply.started":"2022-05-08T20:00:50.387586Z","shell.execute_reply":"2022-05-08T20:00:50.747870Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"CLASS_WEIGHTS = df.groupby(['quantity'])['quantity'].count()\nCLASS_WEIGHTS","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:50.753316Z","iopub.execute_input":"2022-05-08T20:00:50.755284Z","iopub.status.idle":"2022-05-08T20:00:50.773033Z","shell.execute_reply.started":"2022-05-08T20:00:50.755238Z","shell.execute_reply":"2022-05-08T20:00:50.772396Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"quantity\n0     9901\n1    41347\nName: quantity, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Split train and test dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\ntrain_all, test_all = np.split(df.sample(frac=1), [int(.9*len(df))])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:50.776669Z","iopub.execute_input":"2022-05-08T20:00:50.778483Z","iopub.status.idle":"2022-05-08T20:00:50.796979Z","shell.execute_reply.started":"2022-05-08T20:00:50.778446Z","shell.execute_reply":"2022-05-08T20:00:50.796385Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Create loader function with WeightedRandomSampler","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import WeightedRandomSampler\nfrom PIL import Image\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nclass MyDataset(Dataset):\n    def __init__(self, X, y, directory, transform):\n        self.X = X\n        self.y = y\n        self.N = len(y)\n        self.directory = directory\n        self.transform = transform\n    \n    def __len__(self):\n        return self.N\n    \n    def __getitem__(self, idx):\n        image = self.transform(Image.open('{}{}'.format(self.directory, self.X.iloc[idx, 0])))\n        return [image, self.y.iloc[idx]]\n    \ndef loader(X, y, transforms):\n    ds = MyDataset(X, y, '../input/amazon-bin-image-dataset-536434-images-224x224/bin-images-224x224/bin-images-224x224/', transforms)\n    sample_weights = [0] * len(y)\n    for idx, label in enumerate(y):\n        sample_weights[idx] = CLASS_WEIGHTS[label]\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights))\n    return DataLoader(ds, batch_size=256, num_workers=2, sampler=sampler)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:50.800749Z","iopub.execute_input":"2022-05-08T20:00:50.802940Z","iopub.status.idle":"2022-05-08T20:00:51.349728Z","shell.execute_reply.started":"2022-05-08T20:00:50.802903Z","shell.execute_reply":"2022-05-08T20:00:51.349009Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data Augumentation","metadata":{}},{"cell_type":"code","source":"import torchvision\nfrom torchvision import transforms as T\n\ntrain_transforms = T.Compose([\n    T.RandomHorizontalFlip(p=0.1),\n    T.RandomGrayscale(p=0.1),\n    T.RandomAdjustSharpness(2, p=0.1),\n    T.RandomAutocontrast(p=0.1),\n    T.RandomApply([T.ColorJitter(0.5, 0.5, 0.5, 0.5)], p=0.1),\n    T.RandomApply([T.RandomAffine(degrees=0, translate=(0, 0.02), scale=(0.95, 0.99))], p=0.1),\n    T.RandomApply([T.RandomChoice([\n        T.RandomRotation((90, 90)),\n        T.RandomRotation((-90, -90)),\n    ])], p=0.1),\n    T.ToTensor(),\n])\n\nvalid_transforms = T.Compose([\n    T.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:51.351205Z","iopub.execute_input":"2022-05-08T20:00:51.351451Z","iopub.status.idle":"2022-05-08T20:00:51.448843Z","shell.execute_reply.started":"2022-05-08T20:00:51.351418Z","shell.execute_reply":"2022-05-08T20:00:51.448185Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model Design","metadata":{}},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef net(name, pretrained=True):\n    model = timm.create_model(name, pretrained)\n    for param in model.parameters():\n        param.requires_grad = False\n\n    layer = nn.Sequential(\n        nn.BatchNorm1d(model.get_classifier().in_features),\n        nn.Linear(model.get_classifier().in_features, 512, bias=False),\n        nn.ReLU(),\n        nn.BatchNorm1d(512),\n        nn.Dropout(p=0.5, inplace=True),\n        nn.Linear(512, 2, bias=False))\n    if name.startswith('resnet'):\n        model.fc = layer\n    else: # efficientnet\n        model.classifier = layer\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:51.450169Z","iopub.execute_input":"2022-05-08T20:00:51.450435Z","iopub.status.idle":"2022-05-08T20:00:56.388143Z","shell.execute_reply.started":"2022-05-08T20:00:51.450398Z","shell.execute_reply":"2022-05-08T20:00:56.387392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Define validate and train functions","metadata":{}},{"cell_type":"code","source":"import sys\nfrom tqdm import tqdm\n\ndef validate(model, data_loader):\n    model.eval()\n    running_corrects=0\n    for (inputs, labels) in tqdm(data_loader, 'Validate', file=sys.stdout):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        running_corrects += torch.sum(preds == labels.data).item()\n        \n    total_acc = 100.0 * running_corrects / len(data_loader.dataset)\n    print(\"Average accuracy: %f\" % total_acc)\n    return total_acc\n\ndef train(model, train_loader, valid_loader, epochs, optimizer):\n    criterion = nn.CrossEntropyLoss()\n    model.train()\n    previous_accuracy = 0\n    for e in range(1, epochs+1):\n        train_loss = 0\n        for (inputs, labels) in tqdm(train_loader, 'Epoch %s' % e, file=sys.stdout):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        print(f'Loss: {train_loss / len(train_loader)}')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:56.389848Z","iopub.execute_input":"2022-05-08T20:00:56.390087Z","iopub.status.idle":"2022-05-08T20:00:56.401924Z","shell.execute_reply.started":"2022-05-08T20:00:56.390052Z","shell.execute_reply":"2022-05-08T20:00:56.401197Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Train models (You can skip this and download the pretrained ones)\n- Use `efficientnet_b0`\n- Use `StratifiedKFold`\n- Use `Multi-Resolution` training\n- Use `Adam optimizer` with weight decay 1e-4","metadata":{}},{"cell_type":"code","source":"from torch.optim import Adam\nfrom sklearn.model_selection import StratifiedKFold\n\nname = 'efficientnet_b0'\nmodels = []\nIMAGE_SIZES = [56, 112, 224]\nEPOCHS = 10\n\nX = train_all.drop('quantity', axis=1)\ny = train_all.quantity\nskf = StratifiedKFold(n_splits=10)\n\nfor i, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n    print(f'FOLD {i}')\n    t = loader(X.iloc[train_idx], y.iloc[train_idx], train_transforms)\n    v = loader(X.iloc[valid_idx], y.iloc[valid_idx], valid_transforms)\n    model = net(name).to(device)\n    for s in IMAGE_SIZES:\n        optimizer = Adam(model.get_classifier().parameters(), weight_decay=1e-4)\n        model = train(model, t, v, EPOCHS, optimizer)\n\n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download pre-trained image","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/williamhyun/models.git","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:35:39.541862Z","iopub.execute_input":"2022-05-08T20:35:39.542163Z","iopub.status.idle":"2022-05-08T20:36:12.420392Z","shell.execute_reply.started":"2022-05-08T20:35:39.542129Z","shell.execute_reply":"2022-05-08T20:36:12.419496Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Cloning into 'models'...\nremote: Enumerating objects: 16, done.\u001b[K\nremote: Counting objects: 100% (16/16), done.\u001b[K\nremote: Compressing objects: 100% (15/15), done.\u001b[K\nremote: Total 16 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (16/16), 39.56 MiB | 3.20 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls models","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:37:38.374047Z","iopub.execute_input":"2022-05-08T20:37:38.374348Z","iopub.status.idle":"2022-05-08T20:37:39.091063Z","shell.execute_reply.started":"2022-05-08T20:37:38.374298Z","shell.execute_reply":"2022-05-08T20:37:39.090069Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"LICENSE    model0  model2  model4  model6  model8\nREADME.md  model1  model3  model5  model7  model9\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load models\nname = 'efficientnet_b0'\nmodels = []\nfor i in range(10):\n    model = net(name)\n    model.load_state_dict(torch.load(\"models/model%s\" % i))\n    model.to(device)\n    model.eval()\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:38:08.592107Z","iopub.execute_input":"2022-05-08T20:38:08.592683Z","iopub.status.idle":"2022-05-08T20:38:11.175983Z","shell.execute_reply.started":"2022-05-08T20:38:08.592641Z","shell.execute_reply":"2022-05-08T20:38:11.175152Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"X = test_all.drop('quantity', axis=1)\ny = test_all.quantity\n\ntest_dataset = MyDataset(X, y, '../input/amazon-bin-image-dataset-536434-images-224x224/bin-images-224x224/bin-images-224x224/', valid_transforms)\ntest_loader  = DataLoader(test_dataset, batch_size=256, num_workers=2)\n\nfor model in models:\n    model.eval()\n\nrunning_corrects=0\nfor (inputs, labels) in tqdm(test_loader, 'Test', file=sys.stdout):\n    inputs, labels = inputs.to(device), labels.to(device)\n    outputs = torch.mean(torch.stack([m(inputs) for m in models]), dim=0)\n    _, preds = torch.max(outputs, 1)\n    running_corrects += torch.sum(preds == labels.data).item()\naccuracy = 100.0 * running_corrects / len(test_loader.dataset)\n\nprint(\"Average accuracy: %f\" % accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:38:15.690257Z","iopub.execute_input":"2022-05-08T20:38:15.690794Z","iopub.status.idle":"2022-05-08T20:38:53.845634Z","shell.execute_reply.started":"2022-05-08T20:38:15.690752Z","shell.execute_reply":"2022-05-08T20:38:53.844434Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:38<00:00,  1.82s/it]\nAverage accuracy: 98.263415\n","output_type":"stream"}]}]}